#!/bin/bash

# æ®µéšçš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# Usage: ./test-deployment.sh

set -e

GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'

print_status() {
    echo -e "${BLUE}[TEST]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[PASS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

print_error() {
    echo -e "${RED}[FAIL]${NC} $1"
}

# ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’å–å¾—
get_account_info() {
    print_status "Getting account information..."
    ACCOUNT_ID=$(wrangler whoami | grep "Account ID" | tail -1 | awk -F'â”‚' '{print $3}' | tr -d ' ')
    echo "Account ID: $ACCOUNT_ID"
}

# Worker URLã‚’æ›´æ–°
update_worker_urls() {
    print_status "Updating worker URLs in configuration files..."
    
    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’è‡ªå‹•å–å¾—ã—ã¦URLã‚’æ§‹ç¯‰
    SUBDOMAIN_BASE="k-yamada-sir-barrie-co-jp.workers.dev"  # å®Ÿéš›ã®subdomainã«ç½®ãæ›ãˆ
    
    MAIN_URL="https://liver-scraper-main.${SUBDOMAIN_BASE}"
    DETAILS_URL="https://liver-scraper-details.${SUBDOMAIN_BASE}"
    IMAGES_URL="https://liver-scraper-images.${SUBDOMAIN_BASE}"
    
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
    sed -i.bak "s|https://liver-scraper-details.your-account.workers.dev|${DETAILS_URL}|g" wrangler-main.toml
    sed -i.bak "s|https://liver-scraper-images.your-account.workers.dev|${IMAGES_URL}|g" wrangler-main.toml
    sed -i.bak "s|https://liver-scraper-images.your-account.workers.dev|${IMAGES_URL}|g" wrangler-details.toml
    
    print_success "URLs updated:"
    print_success "  Main: ${MAIN_URL}"
    print_success "  Details: ${DETAILS_URL}"
    print_success "  Images: ${IMAGES_URL}"
}

# å€‹åˆ¥Worker ãƒ†ã‚¹ãƒˆ
test_single_worker() {
    local worker_name=$1
    local config_file=$2
    
    print_status "Testing ${worker_name}..."
    
    # ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ†ã‚¹ãƒˆ
    print_status "  Deploying ${worker_name}..."
    if wrangler deploy --config "${config_file}"; then
        print_success "  ${worker_name} deployed successfully"
    else
        print_error "  Failed to deploy ${worker_name}"
        return 1
    fi
    
    # åŸºæœ¬æ¥ç¶šãƒ†ã‚¹ãƒˆ
    sleep 3  # ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†ã‚’å¾…æ©Ÿ
    WORKER_URL=$(wrangler deployments list --config "${config_file}" | grep "https://" | head -1 | awk '{print $2}')
    
    if [ ! -z "$WORKER_URL" ]; then
        print_status "  Testing connection to ${WORKER_URL}..."
        if curl -s -f "${WORKER_URL}" > /dev/null 2>&1; then
            print_success "  ${worker_name} is responding"
        else
            print_warning "  ${worker_name} deployed but not responding (this might be normal for some endpoints)"
        fi
    fi
}

# ãƒ¡ã‚¤ãƒ³Workerã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ
test_main_worker_endpoints() {
    print_status "Testing main worker endpoints..."
    
    MAIN_URL=$(wrangler deployments list --config wrangler-main.toml | grep "https://" | head -1 | awk '{print $2}')
    
    if [ -z "$MAIN_URL" ]; then
        print_error "Could not get main worker URL"
        return 1
    fi
    
    # /status ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ
    print_status "  Testing /status endpoint..."
    if curl -s "${MAIN_URL}/status" | grep -q "main\|details\|images"; then
        print_success "  /status endpoint working"
    else
        print_warning "  /status endpoint response unclear"
    fi
    
    # /minimal-scrape ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ†ã‚¹ãƒˆï¼ˆåŸºæœ¬ãƒ‡ãƒ¼ã‚¿ï¼‰
    print_status "  Testing /minimal-scrape endpoint..."
    RESPONSE=$(curl -s "${MAIN_URL}/minimal-scrape?details=0")
    if echo "$RESPONSE" | grep -q "success"; then
        print_success "  /minimal-scrape endpoint working"
        echo "    Sample response: $(echo "$RESPONSE" | head -c 100)..."
    else
        print_warning "  /minimal-scrape needs authentication setup"
        echo "    Response: $(echo "$RESPONSE" | head -c 200)..."
    fi
}

# ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆè¨­å®šãƒ†ã‚¹ãƒˆ
test_secrets_setup() {
    print_status "Testing secrets configuration..."
    
    if [ -z "$LOGIN_EMAIL" ] || [ -z "$LOGIN_PASSWORD" ]; then
        print_warning "LOGIN_EMAIL and LOGIN_PASSWORD environment variables not set"
        print_status "You can set them and test authentication:"
        echo "  export LOGIN_EMAIL='your-email@example.com'"
        echo "  export LOGIN_PASSWORD='your-password'"
        echo "  wrangler secret put LOGIN_EMAIL --config wrangler-main.toml"
        echo "  wrangler secret put LOGIN_PASSWORD --config wrangler-main.toml"
        return 1
    fi
    
    # ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’è¨­å®š
    print_status "Setting up secrets..."
    for config in wrangler-main.toml wrangler-details.toml wrangler-images.toml; do
        print_status "  Setting secrets for $config..."
        echo "$LOGIN_EMAIL" | wrangler secret put LOGIN_EMAIL --config "$config"
        echo "$LOGIN_PASSWORD" | wrangler secret put LOGIN_PASSWORD --config "$config"
    done
    
    print_success "Secrets configured for all workers"
}

# Workeré–“é€šä¿¡ãƒ†ã‚¹ãƒˆ
test_worker_communication() {
    print_status "Testing worker communication..."
    
    MAIN_URL=$(wrangler deployments list --config wrangler-main.toml | grep "https://" | head -1 | awk '{print $2}')
    
    if [ -z "$MAIN_URL" ]; then
        print_error "Could not get main worker URL for communication test"
        return 1
    fi
    
    # è©³ç´°Workerãƒˆãƒªã‚¬ãƒ¼ãƒ†ã‚¹ãƒˆ
    print_status "  Testing detail worker trigger..."
    RESPONSE=$(curl -s -X POST "${MAIN_URL}/trigger-details")
    if echo "$RESPONSE" | grep -q "success"; then
        print_success "  Detail worker trigger working"
    else
        print_warning "  Detail worker trigger may need authentication setup"
        echo "    Response: $(echo "$RESPONSE" | head -c 100)..."
    fi
}

# ãƒ©ã‚¤ãƒ–ãƒ†ã‚¹ãƒˆï¼ˆå®Ÿéš›ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼‰
test_live_scraping() {
    print_status "Testing live scraping (requires authentication)..."
    
    if [ -z "$LOGIN_EMAIL" ] || [ -z "$LOGIN_PASSWORD" ]; then
        print_warning "Skipping live test - authentication not configured"
        return 1
    fi
    
    MAIN_URL=$(wrangler deployments list --config wrangler-main.toml | grep "https://" | head -1 | awk '{print $2}')
    
    print_status "  Testing minimal scrape with authentication..."
    RESPONSE=$(curl -s "${MAIN_URL}/minimal-scrape?details=0")
    
    if echo "$RESPONSE" | grep -q '"total"' && echo "$RESPONSE" | grep -q '"data"'; then
        TOTAL=$(echo "$RESPONSE" | grep -o '"total":[0-9]*' | cut -d':' -f2)
        print_success "  Live scraping working! Found $TOTAL livers"
    else
        print_warning "  Live scraping may have issues"
        echo "    Response: $(echo "$RESPONSE" | head -c 200)..."
    fi
}

# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç¢ºèª
check_schedules() {
    print_status "Checking cron schedules..."
    
    for config in wrangler-main.toml wrangler-details.toml wrangler-images.toml; do
        SCHEDULE=$(grep -A1 "\[triggers\]" "$config" | grep "crons" | cut -d'"' -f2)
        WORKER_NAME=$(grep "name =" "$config" | cut -d'"' -f2)
        print_status "  $WORKER_NAME: $SCHEDULE"
    done
    
    print_success "All workers have cron schedules configured"
}

# ãƒ­ã‚°ç›£è¦–ãƒ†ã‚¹ãƒˆ
test_logging() {
    print_status "Testing log monitoring..."
    print_status "You can monitor logs in real-time with:"
    echo "  wrangler tail liver-scraper-main"
    echo "  wrangler tail liver-scraper-details"
    echo "  wrangler tail liver-scraper-images"
}

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
main() {
    print_status "ğŸš€ Starting comprehensive deployment test..."
    
    get_account_info
    echo
    
    update_worker_urls
    echo
    
    # Workeré †æ¬¡ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ»ãƒ†ã‚¹ãƒˆ
    test_single_worker "liver-scraper-main" "wrangler-main.toml"
    echo
    
    test_single_worker "liver-scraper-details" "wrangler-details.toml"
    echo
    
    test_single_worker "liver-scraper-images" "wrangler-images.toml"
    echo
    
    # ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ
    test_main_worker_endpoints
    echo
    
    # é€šä¿¡ãƒ†ã‚¹ãƒˆ
    test_worker_communication
    echo
    
    # ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆè¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ãŒã‚ã‚Œã°ï¼‰
    test_secrets_setup
    echo
    
    # ãƒ©ã‚¤ãƒ–ãƒ†ã‚¹ãƒˆï¼ˆèªè¨¼è¨­å®šæ¸ˆã¿ãªã‚‰ï¼‰
    test_live_scraping
    echo
    
    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç¢ºèª
    check_schedules
    echo
    
    # ãƒ­ã‚°ç›£è¦–æƒ…å ±
    test_logging
    echo
    
    print_success "ğŸ‰ Deployment test completed!"
    print_status "Next steps:"
    echo "1. Set up authentication if not done:"
    echo "   export LOGIN_EMAIL='your-email' LOGIN_PASSWORD='your-password'"
    echo "   ./test-deployment.sh  # re-run with auth"
    echo ""
    echo "2. Monitor the first scheduled execution:"
    echo "   wrangler tail liver-scraper-main"
    echo ""
    echo "3. Check data storage:"
    echo "   curl https://liver-scraper-main.YOUR-SUBDOMAIN.workers.dev/status"
}

main